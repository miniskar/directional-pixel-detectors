{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d2990b6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a209a663-ab2b-497d-d184-ea41f65800ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "# Set directory as default system path\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/smart-pixels')"
      ],
      "id": "d2990b6a"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "mpIFDpaF1FpS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad372273-2d39-491d-bcdb-4949ce05f599"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from custom_callbacks import CustomCallback\n",
        "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Dense, BatchNormalization, Flatten, Dropout, LeakyReLU\n",
        "from keras.models import Model\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "mpIFDpaF1FpS"
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(sys.path[-1] + \"/data/resampled200K.csv\")"
      ],
      "metadata": {
        "id": "SftQPop5lGV_"
      },
      "id": "SftQPop5lGV_",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, local_y, pT = data[data.columns[:273]].values.reshape(data.shape[0],13,21,1), data[\"local_y\"].values, data[\"pT\"].values\n",
        "print(X.shape, local_y.shape, pT.shape)"
      ],
      "metadata": {
        "id": "SXyHhcuGlUEZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f850bea9-f84b-4cfd-abc5-4c336b2409e4"
      },
      "id": "SXyHhcuGlUEZ",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200000, 13, 21, 1) (200000,) (200000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_loc_train, Y_loc_test, pT_train, pT_test = train_test_split(\n",
        "    X,\n",
        "    local_y,\n",
        "    pT,\n",
        "    test_size = 0.15,\n",
        "    random_state = 0,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "scaler1 = StandardScaler()\n",
        "X_train = scaler1.fit_transform(X_train.reshape(-1, X_train.shape[0])).reshape(X_train.shape[0],13,21,1)\n",
        "X_test = scaler1.fit_transform(X_test.reshape(-1, X_test.shape[0])).reshape(X_test.shape[0],13,21,1)\n",
        "\n",
        "scaler2 = StandardScaler()\n",
        "Y_loc_train = scaler2.fit_transform(Y_loc_train.reshape(Y_loc_train.shape[0],1)).ravel()\n",
        "Y_loc_test = scaler2.fit_transform(Y_loc_test.reshape(Y_loc_test.shape[0],1)).ravel()"
      ],
      "metadata": {
        "id": "4f5R_SKB84Ls"
      },
      "id": "4f5R_SKB84Ls",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import concatenate\n",
        "from keras.regularizers import L2\n",
        "class ClassificationModel:\n",
        "\n",
        "    def build_image_branch(self,inputA):\n",
        "      regularizer = L2(l2 = 0.0005)\n",
        "      x = Conv2D(32, (3, 3), strides=(1, 1), kernel_initializer= 'he_normal',\n",
        "                 kernel_regularizer = regularizer, activation = 'relu')(inputA)\n",
        "      x = BatchNormalization()(x)\n",
        "      x = Conv2D(16, (3, 3), strides=(1, 1), kernel_initializer= 'he_normal', \n",
        "                  kernel_regularizer = regularizer, activation = 'relu')(x)\n",
        "      x = BatchNormalization()(x)\n",
        "      outputA = Flatten()(x)\n",
        "      return outputA\n",
        "    \n",
        "    def build_image_with_y_loc_branch(self,outputA, inputB):\n",
        "        merged_x = concatenate([outputA, inputB])\n",
        "        regularizer = L2(l2 = 0.0005)\n",
        "        x = Dense(16, kernel_initializer= 'he_normal', \n",
        "                  kernel_regularizer = regularizer, activation = 'relu')(merged_x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dense(8 , kernel_initializer= 'he_normal', \n",
        "                  kernel_regularizer = regularizer, activation = 'relu')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dense(1, activation= \"relu\", name = \"final_output\")(x)\n",
        "\n",
        "        return x\n",
        " \n",
        "    def assemble_model(self):\n",
        "        inputA, inputB = Input ( shape = (13,21,1) ), Input ( shape = (1,) )\n",
        "        outputA = self.build_image_branch(inputA)\n",
        "        final_output = self.build_image_with_y_loc_branch(outputA, inputB)\n",
        "        model = Model(inputs =[inputA, inputB], outputs=final_output, name = \"pT_model\")\n",
        "        print( model.summary() )\n",
        "        return model"
      ],
      "metadata": {
        "id": "GytXjwayqm1t"
      },
      "id": "GytXjwayqm1t",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9059e312",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2037d0f5-14be-4924-f255-441944545237"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"pT_model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_17 (InputLayer)          [(None, 13, 21, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 11, 19, 32)   320         ['input_17[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 11, 19, 32)  128         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 9, 17, 16)    4624        ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 9, 17, 16)   64          ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " flatten_8 (Flatten)            (None, 2448)         0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " input_18 (InputLayer)          [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate)    (None, 2449)         0           ['flatten_8[0][0]',              \n",
            "                                                                  'input_18[0][0]']               \n",
            "                                                                                                  \n",
            " dense_16 (Dense)               (None, 16)           39200       ['concatenate_8[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 16)          64          ['dense_16[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_17 (Dense)               (None, 8)            136         ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 8)           32          ['dense_17[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " final_output (Dense)           (None, 1)            9           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 44,577\n",
            "Trainable params: 44,433\n",
            "Non-trainable params: 144\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "2657/2657 [==============================] - 14s 5ms/step - loss: 3.9253 - accuracy: 0.5006 - val_loss: 2.8915 - val_accuracy: 0.5057\n",
            "Epoch 2/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 2.6113 - accuracy: 0.4990 - val_loss: 2.1618 - val_accuracy: 0.5004\n",
            "Epoch 3/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 2.0608 - accuracy: 0.4992 - val_loss: 1.6580 - val_accuracy: 0.4960\n",
            "Epoch 4/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 1.6976 - accuracy: 0.4983 - val_loss: 1.4115 - val_accuracy: 0.4951\n",
            "Epoch 5/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 1.4495 - accuracy: 0.4979 - val_loss: 1.3163 - val_accuracy: 0.4976\n",
            "Epoch 6/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 1.3323 - accuracy: 0.5010 - val_loss: 1.1621 - val_accuracy: 0.4981\n",
            "Epoch 7/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 1.2849 - accuracy: 0.4997 - val_loss: 1.1260 - val_accuracy: 0.4915\n",
            "Epoch 8/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 1.2638 - accuracy: 0.5007 - val_loss: 1.1650 - val_accuracy: 0.4978\n",
            "Epoch 9/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 1.2498 - accuracy: 0.5016 - val_loss: 1.1535 - val_accuracy: 0.5040\n",
            "Epoch 10/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 1.2006 - accuracy: 0.5026 - val_loss: 1.1107 - val_accuracy: 0.5037\n",
            "Epoch 11/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 1.1580 - accuracy: 0.5028 - val_loss: 1.0978 - val_accuracy: 0.5053\n",
            "Epoch 12/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 1.1503 - accuracy: 0.5027 - val_loss: 1.0253 - val_accuracy: 0.5022\n",
            "Epoch 13/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 1.1116 - accuracy: 0.5003 - val_loss: 1.0210 - val_accuracy: 0.5020\n",
            "Epoch 14/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 1.1135 - accuracy: 0.5016 - val_loss: 1.0183 - val_accuracy: 0.5023\n",
            "Epoch 15/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 1.0860 - accuracy: 0.4995 - val_loss: 0.9877 - val_accuracy: 0.4952\n",
            "Epoch 16/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 1.0533 - accuracy: 0.5024 - val_loss: 0.9146 - val_accuracy: 0.5015\n",
            "Epoch 17/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 1.0152 - accuracy: 0.5026 - val_loss: 0.9368 - val_accuracy: 0.5026\n",
            "Epoch 18/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.9694 - accuracy: 0.5042 - val_loss: 0.8454 - val_accuracy: 0.5089\n",
            "Epoch 19/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.9351 - accuracy: 0.5053 - val_loss: 0.8455 - val_accuracy: 0.5077\n",
            "Epoch 20/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.8733 - accuracy: 0.5043 - val_loss: 0.8365 - val_accuracy: 0.5127\n",
            "Epoch 21/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.8363 - accuracy: 0.5062 - val_loss: 0.8903 - val_accuracy: 0.5083\n",
            "Epoch 22/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.8100 - accuracy: 0.5031 - val_loss: 0.7752 - val_accuracy: 0.5123\n",
            "Epoch 23/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.7724 - accuracy: 0.5087 - val_loss: 0.7655 - val_accuracy: 0.5105\n",
            "Epoch 24/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.7640 - accuracy: 0.5095 - val_loss: 0.7577 - val_accuracy: 0.5146\n",
            "Epoch 25/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.7567 - accuracy: 0.5095 - val_loss: 0.7552 - val_accuracy: 0.5076\n",
            "Epoch 26/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.7516 - accuracy: 0.5128 - val_loss: 1.5609 - val_accuracy: 0.5039\n",
            "Epoch 27/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.7454 - accuracy: 0.5112 - val_loss: 0.7419 - val_accuracy: 0.5169\n",
            "Epoch 28/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.7383 - accuracy: 0.5142 - val_loss: 0.7359 - val_accuracy: 0.5150\n",
            "Epoch 29/200\n",
            "2657/2657 [==============================] - 13s 5ms/step - loss: 0.7352 - accuracy: 0.5141 - val_loss: 0.7320 - val_accuracy: 0.5143\n",
            "Epoch 30/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.7306 - accuracy: 0.5143 - val_loss: 0.7280 - val_accuracy: 0.5121\n",
            "Epoch 31/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.7506 - accuracy: 0.5129 - val_loss: 0.7374 - val_accuracy: 0.5101\n",
            "Epoch 32/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.7660 - accuracy: 0.5114 - val_loss: 0.7845 - val_accuracy: 0.5147\n",
            "Epoch 33/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.7653 - accuracy: 0.5074 - val_loss: 0.8250 - val_accuracy: 0.5139\n",
            "Epoch 34/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.7469 - accuracy: 0.5126 - val_loss: 0.7336 - val_accuracy: 0.5147\n",
            "Epoch 35/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.7294 - accuracy: 0.5176 - val_loss: 0.7387 - val_accuracy: 0.5150\n",
            "Epoch 36/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.7287 - accuracy: 0.5167 - val_loss: 0.7383 - val_accuracy: 0.5173\n",
            "Epoch 37/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.7388 - accuracy: 0.5170 - val_loss: 0.7220 - val_accuracy: 0.5166\n",
            "Epoch 38/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.7192 - accuracy: 0.5203 - val_loss: 0.7201 - val_accuracy: 0.5155\n",
            "Epoch 39/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.7263 - accuracy: 0.5197 - val_loss: 0.7211 - val_accuracy: 0.5141\n",
            "Epoch 40/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.7162 - accuracy: 0.5194 - val_loss: 0.7166 - val_accuracy: 0.5137\n",
            "Epoch 41/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.7259 - accuracy: 0.5183 - val_loss: 0.7210 - val_accuracy: 0.5160\n",
            "Epoch 42/200\n",
            "2657/2657 [==============================] - 13s 5ms/step - loss: 0.7186 - accuracy: 0.5188 - val_loss: 0.7289 - val_accuracy: 0.5138\n",
            "Epoch 43/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.7517 - accuracy: 0.5192 - val_loss: 0.7317 - val_accuracy: 0.5100\n",
            "Epoch 44/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.7527 - accuracy: 0.5169 - val_loss: 0.7190 - val_accuracy: 0.5150\n",
            "Epoch 45/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.7103 - accuracy: 0.5197 - val_loss: 0.7107 - val_accuracy: 0.5164\n",
            "Epoch 46/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.7074 - accuracy: 0.5203 - val_loss: 0.7082 - val_accuracy: 0.5197\n",
            "Epoch 47/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.7058 - accuracy: 0.5215 - val_loss: 0.7091 - val_accuracy: 0.5194\n",
            "Epoch 48/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.7073 - accuracy: 0.5228 - val_loss: 0.7095 - val_accuracy: 0.5182\n",
            "Epoch 49/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.7052 - accuracy: 0.5225 - val_loss: 0.7057 - val_accuracy: 0.5166\n",
            "Epoch 50/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.7028 - accuracy: 0.5258 - val_loss: 0.7052 - val_accuracy: 0.5147\n",
            "Epoch 51/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.7016 - accuracy: 0.5265 - val_loss: 0.7035 - val_accuracy: 0.5195\n",
            "Epoch 52/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.7012 - accuracy: 0.5264 - val_loss: 0.7073 - val_accuracy: 0.5192\n",
            "Epoch 53/200\n",
            "2657/2657 [==============================] - 13s 5ms/step - loss: 0.7009 - accuracy: 0.5283 - val_loss: 0.7049 - val_accuracy: 0.5187\n",
            "Epoch 54/200\n",
            "2657/2657 [==============================] - 13s 5ms/step - loss: 0.7000 - accuracy: 0.5283 - val_loss: 0.7050 - val_accuracy: 0.5180\n",
            "Epoch 55/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.6993 - accuracy: 0.5316 - val_loss: 0.7050 - val_accuracy: 0.5153\n",
            "Epoch 56/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.6988 - accuracy: 0.5302 - val_loss: 0.7057 - val_accuracy: 0.5202\n",
            "Epoch 57/200\n",
            "2657/2657 [==============================] - 14s 5ms/step - loss: 0.6978 - accuracy: 0.5338 - val_loss: 0.7047 - val_accuracy: 0.5124\n",
            "Epoch 58/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.7007 - accuracy: 0.5320 - val_loss: 0.7044 - val_accuracy: 0.5186\n",
            "Epoch 59/200\n",
            "2657/2657 [==============================] - 12s 5ms/step - loss: 0.6972 - accuracy: 0.5364 - val_loss: 0.7046 - val_accuracy: 0.5173\n",
            "Epoch 60/200\n",
            "2657/2657 [==============================] - 13s 5ms/step - loss: 0.6968 - accuracy: 0.5370 - val_loss: 0.7044 - val_accuracy: 0.5178\n",
            "Epoch 61/200\n",
            "2565/2657 [===========================>..] - ETA: 0s - loss: 0.6974 - accuracy: 0.5376"
          ]
        }
      ],
      "source": [
        "model = ClassificationModel().assemble_model()\n",
        "\n",
        "checkpoint_path = \"./models/pT_class_output_model_cp.ckpt\"\n",
        "\n",
        "# Create a callback that saves the model's weights \n",
        "# currently, model weights are saved for each training\n",
        "# to do - update for early stopping\n",
        "# cp_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
        "#                               save_weights_only=True,\n",
        "#                               verbose=1,\n",
        "#                               save_best_only = True)\n",
        "\n",
        "es = EarlyStopping(monitor = \"val_loss\", patience = 10, mode = \"max\")\n",
        "csv_logger = CSVLogger('log.csv', append=True, separator=';')\n",
        "batch_size = 64\n",
        "epochs = 200\n",
        "\n",
        "optim= tf.keras.optimizers.Adam(lr = 0.01, decay = 1-5)\n",
        "\n",
        "model.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "              optimizer = optim,\n",
        "              metrics = [\"accuracy\"])\n",
        "history = model.fit(\n",
        "          x = (X_train, Y_loc_train),\n",
        "          y = pT_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=True,\n",
        "          validation_data = [(X_test, Y_loc_test), pT_test],\n",
        "          callbacks=[csv_logger],\n",
        "          )"
      ],
      "id": "9059e312"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (5,4), dpi = 80)\n",
        "plt.plot(history.history[\"loss\"], color = \"red\")\n",
        "plt.plot(history.history[\"val_loss\"], color = \"black\")\n",
        "plt.legend([\"training\", \"validation\"])\n",
        "plt.minorticks_on()\n",
        "plt.grid(which='major', linestyle='-', linewidth='0.25', alpha=0.5,color='black')\n",
        "plt.grid(which='minor', linestyle=':', linewidth='0.25', alpha=0.5,color='black')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RA9ubQ52JZqs"
      },
      "id": "RA9ubQ52JZqs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "predictions = model.predict([X_test,Y_loc_test], batch_size=batch_size, callbacks=[CustomCallback()])\n",
        "y_preds = predictions.argmax(axis=1)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(pT_test,y_preds))"
      ],
      "metadata": {
        "id": "0UC7ZeQSJ1di"
      },
      "id": "0UC7ZeQSJ1di",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDmFltOvH4cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "ddebe738-da39-4d78-e5b4-68fbcee50681"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start predicting; got log keys: []\n",
            "Stop predicting; got log keys: []\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "predictions = model.predict([X_test,Y_loc_test], batch_size=batch_size, callbacks=[CustomCallback()])\n",
        "y_preds = predictions.argmax(axis=1)\n",
        "cf_matrix = confusion_matrix(pT_test, y_preds)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
        "\n",
        "ax.set_title('Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(['0','1'])\n",
        "ax.yaxis.set_ticklabels(['0','1'])\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ],
      "id": "PDmFltOvH4cc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5touCrBIGKB"
      },
      "outputs": [],
      "source": [
        "# def saving_model(model,\n",
        "#                  filepath:str ='',\n",
        "#                  model_filename:str ='model'):\n",
        "#     \"\"\"\n",
        "#     Helper function to save the trained pruned models in the following format:\n",
        "#         Config -> JSON file format\n",
        "#         Weights -> H5PY file format\n",
        "#     :param model: Keras Model object\n",
        "#     :param filepath: path to store the file in the directory\n",
        "#     :param model_filename: name for the model\n",
        "#     :return: None\n",
        "#     \"\"\" \n",
        "#     # serialize model to JSON\n",
        "#     model_json = model.to_json()\n",
        "#     with open(filepath + \"/\" + model_filename + \".json\", \"w\") as json_file:\n",
        "#         json_file.write(model_json)\n",
        "#     # serialize weights to HDF5\n",
        "#     model.save_weights(filepath + \"/\" + model_filename + \"_weights.h5\")\n",
        "#     print(\"Saved model to disk\")"
      ],
      "id": "L5touCrBIGKB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPGLG0JQQssz"
      },
      "outputs": [],
      "source": [
        "# saving_model(model, filepath = sys.path[-1] + \"/\" + \"models\", model_filename = \"reg_model_pT\")"
      ],
      "id": "nPGLG0JQQssz"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Classification Model- pT",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}